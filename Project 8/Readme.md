#Comparison of Simulated Annealing, MaxWalkSat and Differential Evolution for DTLZ7 Using Less Than Operators

##I. Overview
Engineering is search of optimal solution. The search of a optimal solution involves evaluating by comparison a large number of possible solution variables. Methods like Simulated Annealing, MaxWalkSat and Differential Evolution apply heuristic approach to problem solving, this speeds up the process of problem solving, but does not guarantee the optimal solution. Using "less than" operators on the solution of these algorithms can help us decide optimal solutions between candidates, candidate sets and candidates from different optimizers. We can use this approach in deciding and using algorithms which will suit a particular problem.   

##II. Background
####Simulated Annealing
Simulated annealing is a method for finding a good (not necessarily perfect) solution to an optimization problem. Simulated Annealing is designed to the avoid the local optimal solutions.
The algorithm works as below:
1. Initially randomly chose a solution and name it best.
2. While there is time and solution is not optimum, 
	(i) move around the search space and chose a neighbor and calculate its energy. Update best if there is a better solution.
	(ii) if  not best, decide if we have to jump to better or worst solution based on a probability and repeat (i).

####MaxWalkSat
Unlike Simulated Annealing, MaxWalkSat starts by improving a particular dimension at a time instead of jumping around randomly. In case there is no solution in this dimension which meets a threshold criteria,it chooses and  explores another dimension.

####Differential Evolution
Differential Evolution (DE) optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. DE is suited for multidimensional real-valued functions but does not use the gradient of the problem being optimized. DE does not require the optimization problem to be differentiable as required by classic optimization methods. DE optimizes a problem by maintaining a population of candidate solutions and creating new candidate solutions by combining existing ones saving candidate solution that has the best score.

##III. Introduction
Comparator functions type1, type2 and type3 are used to compare candidate solutions from Simulated Annealing, MaxWalkSat and Differential Evolution.
#### Type I
This comparator is used in all the three algorithms to compare between two candidate solution and decide which one is better amongst them. It replies with a boolean value.
#### Type II
This comparator is used to compare two era in a solution set. This would help us determine if the execution of algorithm is resulting in a better candidate set. If the algorithm does not generate better solution for five consecutive times, we terminate the algorithm.
### Type III
This comparator is used to compare the final eras generated by two different algorithms. This can be used to rank and choose algorithms suiting a particular model.

##IV. Implementation
The project is implemented in the below steps :-
1. The algorithms and models were built as per given specification.
2. For all the three algorithm, type1 operator was used to find out better candidate in a particular era. This was done using binary domination technique.
3. One we have a set of candidates for a era, we use type2 comparator to determine which of the solution is better. The loss of the baseline in compared. If there is no improvement for five consecutive lives, then the algorithm is terminated.
4. When the final frontier of all the three optimizers are obtained,  root mean square distance of the each candidate found from its nearest neighbour in baseline population. The rdivDemo function uses this value to rank the optimizers.

##V. Results
The results from 7th and 20th iteration is pasted below. The results from all the iterations can be seen in results.txt present in this folder.  
Iteration 7  
![root directory] (./images/iteration7.png)
Iteration 20  
![root directory] (./images/iteration20.png)

The results by ranking the three algorithm is displayed below.  
![root directory] (./images/Rdiv.png)

## Threats to Validity
#####1. The algorithms have been tested on only one DTLZ7 model. To conclude one algorithm is better than other based on results from one model would be incorrect. We can try to run algorithm on multiple models and search spaces.
#####2. We have used root mean square of euclidean distance of candidates from nearest neighbour to calculate the ranking of the optimizer. This would be a problem for multi-objective models like DTLZ7 where both the functions move in different directions.
#####3. The results have been seen only for twenty iterations. We can increase the size of population and iterations to get better conclusive results.
#####4. The choice of algorithm often results on the models. So, the results concluded would always be with respect to the model used. This cannot be used to predict performance of an algorithm on any other non-similar model.

##Future Work
#####1. The experiment was run on only one model, running the experiment on multiple models would help us achieve better conclusive results.
#####2. Comparison techniques other than binary domination can be used compare between models.
#####3. Different values of mutation and crossover can be tried
#####4. Experiment can be run for more number of iterations.
#####5. We can try to find the runtime of each of this algorithm when the candidate set is much higher value than one now. 







